{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c63d2793",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-26T00:38:34.116326Z",
     "iopub.status.busy": "2023-06-26T00:38:34.115276Z",
     "iopub.status.idle": "2023-06-26T00:38:42.135694Z",
     "shell.execute_reply": "2023-06-26T00:38:42.134730Z",
     "shell.execute_reply.started": "2023-06-26T00:38:34.116283Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import EfficientNetB7\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers.schedules import PiecewiseConstantDecay\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1658f7cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-26T00:38:42.138399Z",
     "iopub.status.busy": "2023-06-26T00:38:42.137666Z",
     "iopub.status.idle": "2023-06-26T00:38:42.164829Z",
     "shell.execute_reply": "2023-06-26T00:38:42.164005Z",
     "shell.execute_reply.started": "2023-06-26T00:38:42.138364Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load and preprocess the training images\n",
    "devset_path = '/kaggle/input/2023sumdpl302m/devset_images_gt.csv'\n",
    "devset_images_folder = '/kaggle/input/2023sumdpl302m/devset_images/devset_images/'\n",
    "\n",
    "devset_data = pd.read_csv(devset_path)\n",
    "image_ids = devset_data['id'].values\n",
    "labels = devset_data['label'].values\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "train_image_ids, val_image_ids, train_labels, val_labels = train_test_split(image_ids, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Data augmentation generator\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    preprocessing_function=tf.keras.applications.efficientnet.preprocess_input\n",
    ")\n",
    "\n",
    "# Function to load and preprocess an image\n",
    "def load_image(image_id):\n",
    "    image_path = os.path.join(devset_images_folder, str(image_id))\n",
    "    image_extensions = ['.jpg', '.png', '.gif']\n",
    "    for ext in image_extensions:\n",
    "        img_path = image_path + ext\n",
    "        if os.path.exists(img_path):\n",
    "            image = cv2.imread(img_path)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            image = cv2.resize(image, (299, 299))  # Increase image size\n",
    "            image = image.astype('float32')\n",
    "            return image\n",
    "    print(f\"Image not found: {image_path}\")\n",
    "    return None\n",
    "\n",
    "# Function to generate batch of augmented images and labels\n",
    "def generate_augmented_batch(image_ids, labels, batch_size):\n",
    "    while True:\n",
    "        for i in range(0, len(image_ids), batch_size):\n",
    "            batch_image_ids = image_ids[i:i+batch_size]\n",
    "            batch_labels = labels[i:i+batch_size]\n",
    "            \n",
    "            batch_images = []\n",
    "            for image_id in batch_image_ids:\n",
    "                image = load_image(image_id)\n",
    "                if image is not None:\n",
    "                    image = datagen.random_transform(image)\n",
    "                    batch_images.append(image)\n",
    "\n",
    "            yield np.array(batch_images), np.array(batch_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ace263f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-26T00:38:42.166657Z",
     "iopub.status.busy": "2023-06-26T00:38:42.166316Z",
     "iopub.status.idle": "2023-06-26T01:40:56.280183Z",
     "shell.execute_reply": "2023-06-26T01:40:56.279348Z",
     "shell.execute_reply.started": "2023-06-26T00:38:42.166628Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb7_notop.h5\n",
      "258076736/258076736 [==============================] - 8s 0us/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-26 00:39:34.215535: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential/efficientnetb7/block1b_drop/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 330s 2s/step - loss: 1.6732 - accuracy: 0.8542 - val_loss: 1.4631 - val_accuracy: 0.9129\n",
      "Epoch 2/50\n",
      "132/132 [==============================] - 201s 2s/step - loss: 1.2593 - accuracy: 0.9451 - val_loss: 1.2646 - val_accuracy: 0.9186\n",
      "Epoch 3/50\n",
      "132/132 [==============================] - 196s 1s/step - loss: 1.0018 - accuracy: 0.9699 - val_loss: 1.1269 - val_accuracy: 0.9167\n",
      "Epoch 4/50\n",
      "132/132 [==============================] - 234s 2s/step - loss: 0.8099 - accuracy: 0.9785 - val_loss: 1.0364 - val_accuracy: 0.9186\n",
      "Epoch 5/50\n",
      "132/132 [==============================] - 197s 2s/step - loss: 0.6595 - accuracy: 0.9858 - val_loss: 0.8955 - val_accuracy: 0.9148\n",
      "Epoch 6/50\n",
      "132/132 [==============================] - 210s 2s/step - loss: 0.5380 - accuracy: 0.9893 - val_loss: 0.8202 - val_accuracy: 0.9186\n",
      "Epoch 7/50\n",
      "132/132 [==============================] - 181s 1s/step - loss: 0.4402 - accuracy: 0.9889 - val_loss: 0.7141 - val_accuracy: 0.9167\n",
      "Epoch 8/50\n",
      "132/132 [==============================] - 153s 1s/step - loss: 0.3513 - accuracy: 0.9920 - val_loss: 0.6558 - val_accuracy: 0.9186\n",
      "Epoch 9/50\n",
      "132/132 [==============================] - 184s 1s/step - loss: 0.2832 - accuracy: 0.9938 - val_loss: 0.5751 - val_accuracy: 0.9280\n",
      "Epoch 10/50\n",
      "132/132 [==============================] - 209s 2s/step - loss: 0.2239 - accuracy: 0.9957 - val_loss: 0.5919 - val_accuracy: 0.9072\n",
      "Epoch 11/50\n",
      "132/132 [==============================] - 156s 1s/step - loss: 0.1871 - accuracy: 0.9931 - val_loss: 0.5495 - val_accuracy: 0.9062\n",
      "Epoch 12/50\n",
      "132/132 [==============================] - 184s 1s/step - loss: 0.1456 - accuracy: 0.9948 - val_loss: 0.5161 - val_accuracy: 0.9148\n",
      "Epoch 13/50\n",
      "132/132 [==============================] - 182s 1s/step - loss: 0.1254 - accuracy: 0.9917 - val_loss: 0.4217 - val_accuracy: 0.9148\n",
      "Epoch 14/50\n",
      "132/132 [==============================] - 210s 2s/step - loss: 0.0888 - accuracy: 0.9967 - val_loss: 0.4288 - val_accuracy: 0.9233\n",
      "Epoch 15/50\n",
      "132/132 [==============================] - 157s 1s/step - loss: 0.0802 - accuracy: 0.9943 - val_loss: 0.4046 - val_accuracy: 0.9148\n",
      "Epoch 16/50\n",
      "132/132 [==============================] - 209s 2s/step - loss: 0.0611 - accuracy: 0.9957 - val_loss: 0.4409 - val_accuracy: 0.9148\n",
      "Epoch 17/50\n",
      "132/132 [==============================] - 182s 1s/step - loss: 0.0466 - accuracy: 0.9969 - val_loss: 0.4343 - val_accuracy: 0.9110\n",
      "Epoch 18/50\n",
      "132/132 [==============================] - 182s 1s/step - loss: 0.0385 - accuracy: 0.9960 - val_loss: 0.3996 - val_accuracy: 0.9186\n",
      "Epoch 19/50\n",
      "132/132 [==============================] - 155s 1s/step - loss: 0.0336 - accuracy: 0.9960 - val_loss: 0.4204 - val_accuracy: 0.9205\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the EfficientNetB7 model\n",
    "base_model = EfficientNetB7(weights='imagenet', include_top=False, input_shape=(299, 299, 3))  \n",
    "\n",
    "# Unfreeze more layers in the base model\n",
    "fine_tune_at = 600  # Update the number of layers to fine-tune\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Create a new model on top of the base model\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dropout(0.3),  \n",
    "    Dense(1024, activation='relu', kernel_regularizer=regularizers.l2(0.001)),  \n",
    "    Dropout(0.3),  # Update dropout rate\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Define the learning rate schedule\n",
    "initial_learning_rate = 0.0001\n",
    "lr_schedule = PiecewiseConstantDecay(\n",
    "    boundaries=[10000, 20000],  \n",
    "    values=[initial_learning_rate, initial_learning_rate * 0.1, initial_learning_rate * 0.01]\n",
    ")\n",
    "optimizer = Adam(learning_rate=lr_schedule)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Train the model with data augmentation\n",
    "batch_size = 32\n",
    "epochs = 50  \n",
    "\n",
    "# Use tf.data.Dataset for efficient data loading\n",
    "train_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: generate_augmented_batch(train_image_ids, train_labels, batch_size),\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(None, 299, 299, 3), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(None,), dtype=tf.float32),\n",
    "    )\n",
    ")\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: generate_augmented_batch(val_image_ids, val_labels, batch_size),\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(None, 299, 299, 3), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(None,), dtype=tf.float32),\n",
    "    )\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    steps_per_epoch=len(train_image_ids) // batch_size,\n",
    "    validation_steps=len(val_image_ids) // batch_size,\n",
    "    epochs=epochs,\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99770d75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-26T01:40:56.285282Z",
     "iopub.status.busy": "2023-06-26T01:40:56.284537Z",
     "iopub.status.idle": "2023-06-26T01:41:21.520607Z",
     "shell.execute_reply": "2023-06-26T01:41:21.519569Z",
     "shell.execute_reply.started": "2023-06-26T01:40:56.285249Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load and preprocess the test images\n",
    "testset_path = '/kaggle/input/2023sumdpl302m/test.csv'\n",
    "testset_images_folder = '/kaggle/input/2023sumdpl302m/testset_images/testset_images/'\n",
    "\n",
    "testset_data = pd.read_csv(testset_path)\n",
    "test_image_ids = testset_data['image_id'].values\n",
    "\n",
    "test_images = []\n",
    "for image_id in test_image_ids:\n",
    "    image_path = os.path.join(testset_images_folder, str(image_id))\n",
    "\n",
    "    if not any(image_path.lower().endswith(ext) for ext in ['.jpg', '.jpeg', '.png', '.gif']):\n",
    "        image_path += '.jpg'\n",
    "\n",
    "    try:\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    except:\n",
    "        image_path = image_path[:-4] + '.png'\n",
    "        try:\n",
    "            image = cv2.imread(image_path)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        except:\n",
    "            print(f\"Image not found: {image_path}\")\n",
    "            continue\n",
    "\n",
    "    image = cv2.resize(image, (299, 299))\n",
    "    image = image.astype('float32')\n",
    "    test_images.append(image)\n",
    "\n",
    "test_images = np.array(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd35be72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-26T01:41:21.528169Z",
     "iopub.status.busy": "2023-06-26T01:41:21.525699Z",
     "iopub.status.idle": "2023-06-26T01:41:50.364314Z",
     "shell.execute_reply": "2023-06-26T01:41:50.363357Z",
     "shell.execute_reply.started": "2023-06-26T01:41:21.528136Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 21s 387ms/step\n",
      "              id  label\n",
      "0     3483809003    1.0\n",
      "1     3712805295    0.0\n",
      "2      379845620    0.0\n",
      "3     7343264988    1.0\n",
      "4     3843337492    1.0\n",
      "...          ...    ...\n",
      "1315  6452132743    0.0\n",
      "1316   244899140    0.0\n",
      "1317  3073018258    0.0\n",
      "1318    49525361    0.0\n",
      "1319   537780925    0.0\n",
      "\n",
      "[1320 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_images)\n",
    "predicted_labels = np.round(predictions).flatten()\n",
    "\n",
    "predicted_df = pd.DataFrame({'id': test_image_ids, 'label': predicted_labels})\n",
    "print(predicted_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0bec342",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-26T01:41:50.366449Z",
     "iopub.status.busy": "2023-06-26T01:41:50.365860Z",
     "iopub.status.idle": "2023-06-26T01:41:50.379623Z",
     "shell.execute_reply": "2023-06-26T01:41:50.378677Z",
     "shell.execute_reply.started": "2023-06-26T01:41:50.366414Z"
    }
   },
   "outputs": [],
   "source": [
    "predicted_df.to_csv('test33.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
